{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Keras LIB\n",
    "---\n",
    "- Tensorflow 기반의 Keras 패키지\n",
    "- 기본 데이터 : Tensor 타입\n",
    "- 모델을 직접 설계/생성 해야함!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.datasets import load_iris"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "# 데이터 로딩\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, target.shape, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [1] 모델 구성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "model = keras.Sequential(name='MYModel')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "# 첫번째 층은 반드시 입력정보 파라미터 설정해 줘야함 => input_shape=( 튜플 ) or input_dim=숫자\n",
    "# 각 노드 : 4개 입력 / 1개 출력\n",
    "# 총 10개가 다음 층의 입력이 됨\n",
    "l_1 = Dense(10, activation='relu', input_shape=(4,))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "# 각 노드(퍼셉트론 or 유닛) : 여기선 10개 입력받음, 출력 50개\n",
    "l_2 = Dense(50, activation='relu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "# 총 3개 출력\n",
    "l_3 = Dense(3, activation='softmax')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "model.add(l_1)\n",
    "model.add(l_2)\n",
    "model.add(l_3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MYModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 50)                550       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 753\n",
      "Trainable params: 753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 구성 확인 => summary()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [2] 모델 생성\n",
    "- 손실함수, 최적화 기법, 성능평가항목 설정\n",
    "- compile() 메서드 사용\n",
    "    - optimizer : string 타입의 최적화기법명 입력 또는 객체 입력 <- 기본값 사용하지 않는 경우\n",
    "    - loss : 손실함수로 string 타입의 이름 입력\n",
    "        - 분류 : categorical_crossentropy, sparse_categorical_crossentropy, binary_crossentropy\n",
    "        - 회귀 : mae, mse, rmse...\n",
    "    - metrics : 모델 평가 항목\n",
    "        - accuracy, mse, mae, rmse..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### [3] 학습\n",
    "- fit() 메서드 사용\n",
    "    - 훈련용 데이터\n",
    "    - 훈련용 타겟\n",
    "    - 학습 횟수(epochs) : 처음-끝까지\n",
    "    - bacth_size : 한번에 학습할 양(default=32)\n",
    "    - validation_split / validation_data = ( , ) : 검증 데이터 설정\n",
    "    - callbacks : 이벤트 처리 함수 목록(리스트로 입력 / 예: 학습중단 이벤트, 모델 검증 및 저장 이벤트)\n",
    "    - verbose : 학습 과정 출력 여부 설정(default=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.8333\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.8333\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8200\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8267\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4779 - accuracy: 0.8200\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.9000\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.4518 - accuracy: 0.9600\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.9600\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4267 - accuracy: 0.9533\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4168 - accuracy: 0.9333\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4057 - accuracy: 0.9533\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.9533\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3856 - accuracy: 0.9533\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3777 - accuracy: 0.9533\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3664 - accuracy: 0.9600\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3577 - accuracy: 0.9667\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3501 - accuracy: 0.9733\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3403 - accuracy: 0.9733\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.9600\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.9600\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.9600\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3082 - accuracy: 0.9733\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.9800\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2929 - accuracy: 0.9733\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2897 - accuracy: 0.9600\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2724 - accuracy: 0.9800\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2661 - accuracy: 0.9800\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2589 - accuracy: 0.9733\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2527 - accuracy: 0.9733\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.9733\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9800\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2371 - accuracy: 0.9800\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.9800\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2241 - accuracy: 0.9733\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.9733\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9800\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.9800\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.9800\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.9733\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1895 - accuracy: 0.9800\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.9800\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.9800\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.9800\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.9733\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1716 - accuracy: 0.9800\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1691 - accuracy: 0.9800\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1634 - accuracy: 0.9800\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1608 - accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1587 - accuracy: 0.9800\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1549 - accuracy: 0.9800\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9800\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1495 - accuracy: 0.9733\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1457 - accuracy: 0.9800\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1440 - accuracy: 0.9800\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1420 - accuracy: 0.9800\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9800\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1375 - accuracy: 0.9800\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1351 - accuracy: 0.9733\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1335 - accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1315 - accuracy: 0.9800\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1269 - accuracy: 0.9800\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9800\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1241 - accuracy: 0.9733\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1228 - accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1197 - accuracy: 0.9800\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1177 - accuracy: 0.9800\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.9733\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1146 - accuracy: 0.9800\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1135 - accuracy: 0.9800\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1115 - accuracy: 0.9800\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1103 - accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1092 - accuracy: 0.9800\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1081 - accuracy: 0.9800\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9800\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1056 - accuracy: 0.9800\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9800\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.9800\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1023 - accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9733\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1004 - accuracy: 0.9800\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9800\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9733\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0967 - accuracy: 0.9800\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9800\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9800\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0956 - accuracy: 0.9800\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.9800\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9800\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0915 - accuracy: 0.9800\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9733\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.9800\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9733\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9800\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1d961091308>"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, target, epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[9.96501446e-01, 3.49860615e-03, 3.27203847e-10],\n       [9.95160162e-01, 4.83983057e-03, 1.11109355e-09],\n       [9.95000005e-01, 5.00004506e-03, 1.37690293e-09],\n       [9.92994130e-01, 7.00582843e-03, 3.69884545e-09],\n       [9.96166766e-01, 3.83319543e-03, 4.34244141e-10],\n       [9.96121109e-01, 3.87887890e-03, 2.40174464e-10],\n       [9.93606687e-01, 6.39334787e-03, 2.49981258e-09],\n       [9.95646179e-01, 4.35377471e-03, 6.61445121e-10],\n       [9.92131412e-01, 7.86857959e-03, 6.76320511e-09],\n       [9.95158970e-01, 4.84103849e-03, 1.10385756e-09],\n       [9.97248232e-01, 2.75168847e-03, 1.21124152e-10],\n       [9.93748784e-01, 6.25120709e-03, 1.91842831e-09],\n       [9.95068908e-01, 4.93110670e-03, 1.33049727e-09],\n       [9.93804693e-01, 6.19531516e-03, 3.81689125e-09],\n       [9.98669744e-01, 1.33025215e-03, 1.05348456e-11],\n       [9.97967660e-01, 2.03235331e-03, 2.89671290e-11],\n       [9.97643530e-01, 2.35648174e-03, 7.36404202e-11],\n       [9.96379197e-01, 3.62080289e-03, 3.57430391e-10],\n       [9.97412503e-01, 2.58753635e-03, 7.18422127e-11],\n       [9.96005476e-01, 3.99449328e-03, 3.83616999e-10],\n       [9.96286511e-01, 3.71345016e-03, 2.86070723e-10],\n       [9.95747983e-01, 4.25205473e-03, 4.64539268e-10],\n       [9.96064603e-01, 3.93544277e-03, 6.68869793e-10],\n       [9.88704383e-01, 1.12956343e-02, 4.21539470e-09],\n       [9.90647376e-01, 9.35260765e-03, 4.89856200e-09],\n       [9.93771255e-01, 6.22871425e-03, 1.70132575e-09],\n       [9.93888736e-01, 6.11125212e-03, 1.35518674e-09],\n       [9.96520638e-01, 3.47942277e-03, 2.94150204e-10],\n       [9.96806860e-01, 3.19312513e-03, 2.46541482e-10],\n       [9.92904961e-01, 7.09503749e-03, 3.22158411e-09],\n       [9.93657172e-01, 6.34275516e-03, 2.34980213e-09],\n       [9.95928466e-01, 4.07149876e-03, 3.04045122e-10],\n       [9.96870458e-01, 3.12959822e-03, 1.67705017e-10],\n       [9.97895718e-01, 2.10426794e-03, 4.35981043e-11],\n       [9.94990051e-01, 5.00988681e-03, 1.20577570e-09],\n       [9.96659994e-01, 3.34004220e-03, 3.61612434e-10],\n       [9.97891843e-01, 2.10818159e-03, 5.96206418e-11],\n       [9.95889127e-01, 4.11092304e-03, 5.71652892e-10],\n       [9.92988944e-01, 7.01104198e-03, 4.80423523e-09],\n       [9.96087670e-01, 3.91229754e-03, 4.58360572e-10],\n       [9.96359169e-01, 3.64075927e-03, 3.97594457e-10],\n       [9.84283090e-01, 1.57169383e-02, 2.78660668e-08],\n       [9.93167818e-01, 6.83218800e-03, 4.09201339e-09],\n       [9.90423501e-01, 9.57647059e-03, 3.11231108e-09],\n       [9.92751122e-01, 7.24892225e-03, 1.51697188e-09],\n       [9.93835330e-01, 6.16465230e-03, 2.09688511e-09],\n       [9.95685220e-01, 4.31485660e-03, 4.63511673e-10],\n       [9.93859470e-01, 6.14060648e-03, 2.56818566e-09],\n       [9.96945560e-01, 3.05442885e-03, 1.74197962e-10],\n       [9.96014833e-01, 3.98515724e-03, 5.52479062e-10],\n       [1.48113340e-03, 9.88890052e-01, 9.62881837e-03],\n       [1.57735671e-03, 9.67698753e-01, 3.07238959e-02],\n       [7.64898141e-04, 9.45258975e-01, 5.39761856e-02],\n       [2.09999923e-03, 8.59614372e-01, 1.38285607e-01],\n       [8.63836438e-04, 9.04250085e-01, 9.48859975e-02],\n       [1.63173070e-03, 8.46837223e-01, 1.51531026e-01],\n       [9.61155398e-04, 9.00123954e-01, 9.89149660e-02],\n       [2.25137807e-02, 9.68801737e-01, 8.68445635e-03],\n       [1.66755065e-03, 9.75716472e-01, 2.26159282e-02],\n       [2.92193610e-03, 8.82266343e-01, 1.14811733e-01],\n       [7.71635398e-03, 9.55244541e-01, 3.70390639e-02],\n       [2.01762258e-03, 9.44175541e-01, 5.38067371e-02],\n       [4.49743029e-03, 9.81682420e-01, 1.38201164e-02],\n       [1.01898122e-03, 8.42011631e-01, 1.56969428e-01],\n       [1.05388714e-02, 9.83292520e-01, 6.16854569e-03],\n       [2.10408540e-03, 9.89675581e-01, 8.22044071e-03],\n       [1.05064968e-03, 7.30599284e-01, 2.68350154e-01],\n       [7.30135711e-03, 9.83645558e-01, 9.05303005e-03],\n       [3.68290901e-04, 5.82310915e-01, 4.17320818e-01],\n       [5.40745258e-03, 9.76382613e-01, 1.82099938e-02],\n       [2.13021980e-04, 4.00461763e-01, 5.99325240e-01],\n       [3.86124244e-03, 9.85963404e-01, 1.01753194e-02],\n       [2.19653404e-04, 4.60051835e-01, 5.39728582e-01],\n       [1.65118976e-03, 9.17003632e-01, 8.13451856e-02],\n       [2.61079613e-03, 9.85613406e-01, 1.17757125e-02],\n       [1.91699469e-03, 9.84549046e-01, 1.35339871e-02],\n       [8.43723014e-04, 9.37172413e-01, 6.19838536e-02],\n       [2.67551746e-04, 6.75000072e-01, 3.24732393e-01],\n       [1.06623385e-03, 8.44428301e-01, 1.54505521e-01],\n       [2.94788815e-02, 9.68687177e-01, 1.83403725e-03],\n       [5.68387005e-03, 9.73782003e-01, 2.05341540e-02],\n       [1.06007904e-02, 9.80252504e-01, 9.14671365e-03],\n       [5.43351565e-03, 9.83272910e-01, 1.12936171e-02],\n       [5.79621155e-05, 1.65479317e-01, 8.34462702e-01],\n       [9.16820543e-04, 6.26881003e-01, 3.72202218e-01],\n       [1.47520693e-03, 9.23718870e-01, 7.48059079e-02],\n       [1.04374660e-03, 9.57696259e-01, 4.12600599e-02],\n       [1.17364235e-03, 9.01344895e-01, 9.74814594e-02],\n       [3.99880018e-03, 9.67694938e-01, 2.83062346e-02],\n       [2.69802124e-03, 9.10823703e-01, 8.64782110e-02],\n       [1.97588606e-03, 8.29999447e-01, 1.68024644e-01],\n       [1.39490620e-03, 9.09605265e-01, 8.89998898e-02],\n       [3.96954967e-03, 9.75106239e-01, 2.09241826e-02],\n       [1.98294409e-02, 9.71305966e-01, 8.86462163e-03],\n       [2.45131133e-03, 9.11478698e-01, 8.60700607e-02],\n       [4.44690092e-03, 9.75687027e-01, 1.98660158e-02],\n       [3.08824237e-03, 9.55047488e-01, 4.18643281e-02],\n       [2.63592484e-03, 9.78466868e-01, 1.88972559e-02],\n       [4.46539260e-02, 9.52890098e-01, 2.45601987e-03],\n       [3.24203307e-03, 9.59360480e-01, 3.73974219e-02],\n       [6.26287573e-08, 2.89013330e-03, 9.97109830e-01],\n       [4.48408127e-06, 2.63991114e-02, 9.73596394e-01],\n       [9.27344786e-07, 2.29932275e-02, 9.77005780e-01],\n       [4.53462098e-06, 3.62106562e-02, 9.63784873e-01],\n       [2.70276331e-07, 6.64915331e-03, 9.93350565e-01],\n       [8.73993358e-08, 5.80535783e-03, 9.94194567e-01],\n       [2.71733134e-05, 4.72502001e-02, 9.52722609e-01],\n       [1.20580341e-06, 2.79997196e-02, 9.71999109e-01],\n       [9.95527444e-07, 1.58276074e-02, 9.84171450e-01],\n       [1.80423100e-07, 8.99647735e-03, 9.91003275e-01],\n       [5.01339964e-05, 2.47541040e-01, 7.52408862e-01],\n       [6.18744252e-06, 5.07438667e-02, 9.49249923e-01],\n       [3.62282685e-06, 4.99388725e-02, 9.50057507e-01],\n       [1.87441526e-06, 1.38853872e-02, 9.86112773e-01],\n       [4.57507923e-07, 7.39590218e-03, 9.92603719e-01],\n       [1.91206345e-06, 2.60009263e-02, 9.73997176e-01],\n       [1.61828921e-05, 1.03711680e-01, 8.96272123e-01],\n       [4.83502617e-07, 2.29683034e-02, 9.77031171e-01],\n       [9.83089077e-09, 1.91872241e-03, 9.98081326e-01],\n       [3.62808751e-05, 1.13842636e-01, 8.86121094e-01],\n       [7.61957381e-07, 1.89542621e-02, 9.81045008e-01],\n       [5.41324835e-06, 2.75058839e-02, 9.72488701e-01],\n       [7.80127891e-08, 5.51888067e-03, 9.94481087e-01],\n       [6.67915374e-05, 2.41954818e-01, 7.57978439e-01],\n       [3.01093496e-06, 4.08209153e-02, 9.59176123e-01],\n       [1.19721890e-05, 1.35474458e-01, 8.64513576e-01],\n       [1.14134149e-04, 3.23536277e-01, 6.76349580e-01],\n       [1.13710310e-04, 3.03353667e-01, 6.96532607e-01],\n       [5.20493643e-07, 9.18521825e-03, 9.90814269e-01],\n       [5.55850311e-05, 3.51494193e-01, 6.48450255e-01],\n       [1.41098849e-06, 3.51663232e-02, 9.64832306e-01],\n       [1.27065841e-05, 2.45846063e-01, 7.54141271e-01],\n       [3.47272447e-07, 7.56661454e-03, 9.92433071e-01],\n       [2.24921678e-04, 4.67252135e-01, 5.32522917e-01],\n       [1.87162113e-05, 7.30943456e-02, 9.26886976e-01],\n       [3.02003116e-07, 1.69927962e-02, 9.83006835e-01],\n       [3.40614491e-07, 7.28133321e-03, 9.92718339e-01],\n       [1.83529901e-05, 1.05918318e-01, 8.94063294e-01],\n       [1.45255108e-04, 3.33905548e-01, 6.65949225e-01],\n       [1.02960685e-05, 1.12948127e-01, 8.87041509e-01],\n       [3.03794621e-07, 8.76245368e-03, 9.91237283e-01],\n       [1.08008117e-05, 1.27379388e-01, 8.72609794e-01],\n       [4.48408127e-06, 2.63991114e-02, 9.73596394e-01],\n       [2.25419882e-07, 7.21512642e-03, 9.92784619e-01],\n       [1.84551610e-07, 6.40687952e-03, 9.93592918e-01],\n       [3.07941968e-06, 4.52516116e-02, 9.54745293e-01],\n       [1.11590925e-05, 7.22013637e-02, 9.27787483e-01],\n       [1.69988471e-05, 1.17118627e-01, 8.82864356e-01],\n       [1.47812091e-06, 1.87575892e-02, 9.81240928e-01],\n       [3.21541811e-05, 1.11701593e-01, 8.88266265e-01]], dtype=float32)"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0861 - accuracy: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.08613274991512299, 0.9800000190734863]"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}