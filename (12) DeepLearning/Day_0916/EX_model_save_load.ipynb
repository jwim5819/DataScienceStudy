{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 저장과 복원\n",
    "---\n",
    "- 방법 1) 모델 전체 저장(모델 구조, 가중치, 변수, ...)\n",
    "    - save_model()\n",
    "    - 복원 시 추가 작업이 필요없고, 모델 파일만 로딩해서 사용 가능\n",
    "- 방법 2) 가중치만 저장\n",
    "    - save_weights()\n",
    "    - 복원 시 모델 구조(Architechture) 생성 후 가중치 적용\n",
    "- 방법 3) 모델 전체 또는 가중치 자동 저장\n",
    "    - fit()에서 ModelCheckPoint Event에 대한 callback 등록\n",
    "    - save_best_only=True : 모니터링 기준에 따라서 좋은 성능의 모델만 저장\n",
    "    - save_weight_only=True : 가중치만 저장\n",
    "- 파일 또는 폴더로 저장\n",
    "    - 파일 확장자가 없을 시 폴더로 저장됨\n",
    "    - 파일 확장자\n",
    "        - h5 / hdf5 : HDF5 포맷으로 모델 또는 가중치 저장\n",
    "        - ckpf : 체크포인트 파일 형태로 저장\n",
    "        - pd : 모델 저장"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import set_random_seed, plot_model\n",
    "from keras.models import save_model, load_model\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "set_random_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 준비 및 로딩 / 모델 생성"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [
    {
     "data": {
      "text/plain": "((150, 4), (150,))"
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_iris()\n",
    "x_train = df.data\n",
    "y_train = df.target\n",
    "x_train.shape, y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "data": {
      "text/plain": "(array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n ['sepal length (cm)',\n  'sepal width (cm)',\n  'petal length (cm)',\n  'petal width (cm)'])"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target_names, df.feature_names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "# encoder = OneHotEncoder()\n",
    "# encoder.fit([y_train])\n",
    "# encoder.transform([y_train])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.66666667, 0.06779661, 0.04166667],\n       [0.30555556, 0.79166667, 0.11864407, 0.125     ],\n       [0.08333333, 0.58333333, 0.06779661, 0.08333333],\n       [0.19444444, 0.58333333, 0.08474576, 0.04166667],\n       [0.02777778, 0.375     , 0.06779661, 0.04166667],\n       [0.16666667, 0.45833333, 0.08474576, 0.        ],\n       [0.30555556, 0.70833333, 0.08474576, 0.04166667],\n       [0.13888889, 0.58333333, 0.10169492, 0.04166667],\n       [0.13888889, 0.41666667, 0.06779661, 0.        ],\n       [0.        , 0.41666667, 0.01694915, 0.        ],\n       [0.41666667, 0.83333333, 0.03389831, 0.04166667],\n       [0.38888889, 1.        , 0.08474576, 0.125     ],\n       [0.30555556, 0.79166667, 0.05084746, 0.125     ],\n       [0.22222222, 0.625     , 0.06779661, 0.08333333],\n       [0.38888889, 0.75      , 0.11864407, 0.08333333],\n       [0.22222222, 0.75      , 0.08474576, 0.08333333],\n       [0.30555556, 0.58333333, 0.11864407, 0.04166667],\n       [0.22222222, 0.70833333, 0.08474576, 0.125     ],\n       [0.08333333, 0.66666667, 0.        , 0.04166667],\n       [0.22222222, 0.54166667, 0.11864407, 0.16666667],\n       [0.13888889, 0.58333333, 0.15254237, 0.04166667],\n       [0.19444444, 0.41666667, 0.10169492, 0.04166667],\n       [0.19444444, 0.58333333, 0.10169492, 0.125     ],\n       [0.25      , 0.625     , 0.08474576, 0.04166667],\n       [0.25      , 0.58333333, 0.06779661, 0.04166667],\n       [0.11111111, 0.5       , 0.10169492, 0.04166667],\n       [0.13888889, 0.45833333, 0.10169492, 0.04166667],\n       [0.30555556, 0.58333333, 0.08474576, 0.125     ],\n       [0.25      , 0.875     , 0.08474576, 0.        ],\n       [0.33333333, 0.91666667, 0.06779661, 0.04166667],\n       [0.16666667, 0.45833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.5       , 0.03389831, 0.04166667],\n       [0.33333333, 0.625     , 0.05084746, 0.04166667],\n       [0.16666667, 0.66666667, 0.06779661, 0.        ],\n       [0.02777778, 0.41666667, 0.05084746, 0.04166667],\n       [0.22222222, 0.58333333, 0.08474576, 0.04166667],\n       [0.19444444, 0.625     , 0.05084746, 0.08333333],\n       [0.05555556, 0.125     , 0.05084746, 0.08333333],\n       [0.02777778, 0.5       , 0.05084746, 0.04166667],\n       [0.19444444, 0.625     , 0.10169492, 0.20833333],\n       [0.22222222, 0.75      , 0.15254237, 0.125     ],\n       [0.13888889, 0.41666667, 0.06779661, 0.08333333],\n       [0.22222222, 0.75      , 0.10169492, 0.04166667],\n       [0.08333333, 0.5       , 0.06779661, 0.04166667],\n       [0.27777778, 0.70833333, 0.08474576, 0.04166667],\n       [0.19444444, 0.54166667, 0.06779661, 0.04166667],\n       [0.75      , 0.5       , 0.62711864, 0.54166667],\n       [0.58333333, 0.5       , 0.59322034, 0.58333333],\n       [0.72222222, 0.45833333, 0.66101695, 0.58333333],\n       [0.33333333, 0.125     , 0.50847458, 0.5       ],\n       [0.61111111, 0.33333333, 0.61016949, 0.58333333],\n       [0.38888889, 0.33333333, 0.59322034, 0.5       ],\n       [0.55555556, 0.54166667, 0.62711864, 0.625     ],\n       [0.16666667, 0.16666667, 0.38983051, 0.375     ],\n       [0.63888889, 0.375     , 0.61016949, 0.5       ],\n       [0.25      , 0.29166667, 0.49152542, 0.54166667],\n       [0.19444444, 0.        , 0.42372881, 0.375     ],\n       [0.44444444, 0.41666667, 0.54237288, 0.58333333],\n       [0.47222222, 0.08333333, 0.50847458, 0.375     ],\n       [0.5       , 0.375     , 0.62711864, 0.54166667],\n       [0.36111111, 0.375     , 0.44067797, 0.5       ],\n       [0.66666667, 0.45833333, 0.57627119, 0.54166667],\n       [0.36111111, 0.41666667, 0.59322034, 0.58333333],\n       [0.41666667, 0.29166667, 0.52542373, 0.375     ],\n       [0.52777778, 0.08333333, 0.59322034, 0.58333333],\n       [0.36111111, 0.20833333, 0.49152542, 0.41666667],\n       [0.44444444, 0.5       , 0.6440678 , 0.70833333],\n       [0.5       , 0.33333333, 0.50847458, 0.5       ],\n       [0.55555556, 0.20833333, 0.66101695, 0.58333333],\n       [0.5       , 0.33333333, 0.62711864, 0.45833333],\n       [0.58333333, 0.375     , 0.55932203, 0.5       ],\n       [0.63888889, 0.41666667, 0.57627119, 0.54166667],\n       [0.69444444, 0.33333333, 0.6440678 , 0.54166667],\n       [0.66666667, 0.41666667, 0.6779661 , 0.66666667],\n       [0.47222222, 0.375     , 0.59322034, 0.58333333],\n       [0.38888889, 0.25      , 0.42372881, 0.375     ],\n       [0.33333333, 0.16666667, 0.47457627, 0.41666667],\n       [0.33333333, 0.16666667, 0.45762712, 0.375     ],\n       [0.41666667, 0.29166667, 0.49152542, 0.45833333],\n       [0.47222222, 0.29166667, 0.69491525, 0.625     ],\n       [0.30555556, 0.41666667, 0.59322034, 0.58333333],\n       [0.47222222, 0.58333333, 0.59322034, 0.625     ],\n       [0.66666667, 0.45833333, 0.62711864, 0.58333333],\n       [0.55555556, 0.125     , 0.57627119, 0.5       ],\n       [0.36111111, 0.41666667, 0.52542373, 0.5       ],\n       [0.33333333, 0.20833333, 0.50847458, 0.5       ],\n       [0.33333333, 0.25      , 0.57627119, 0.45833333],\n       [0.5       , 0.41666667, 0.61016949, 0.54166667],\n       [0.41666667, 0.25      , 0.50847458, 0.45833333],\n       [0.19444444, 0.125     , 0.38983051, 0.375     ],\n       [0.36111111, 0.29166667, 0.54237288, 0.5       ],\n       [0.38888889, 0.41666667, 0.54237288, 0.45833333],\n       [0.38888889, 0.375     , 0.54237288, 0.5       ],\n       [0.52777778, 0.375     , 0.55932203, 0.5       ],\n       [0.22222222, 0.20833333, 0.33898305, 0.41666667],\n       [0.38888889, 0.33333333, 0.52542373, 0.5       ],\n       [0.55555556, 0.54166667, 0.84745763, 1.        ],\n       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n       [0.77777778, 0.41666667, 0.83050847, 0.83333333],\n       [0.55555556, 0.375     , 0.77966102, 0.70833333],\n       [0.61111111, 0.41666667, 0.81355932, 0.875     ],\n       [0.91666667, 0.41666667, 0.94915254, 0.83333333],\n       [0.16666667, 0.20833333, 0.59322034, 0.66666667],\n       [0.83333333, 0.375     , 0.89830508, 0.70833333],\n       [0.66666667, 0.20833333, 0.81355932, 0.70833333],\n       [0.80555556, 0.66666667, 0.86440678, 1.        ],\n       [0.61111111, 0.5       , 0.69491525, 0.79166667],\n       [0.58333333, 0.29166667, 0.72881356, 0.75      ],\n       [0.69444444, 0.41666667, 0.76271186, 0.83333333],\n       [0.38888889, 0.20833333, 0.6779661 , 0.79166667],\n       [0.41666667, 0.33333333, 0.69491525, 0.95833333],\n       [0.58333333, 0.5       , 0.72881356, 0.91666667],\n       [0.61111111, 0.41666667, 0.76271186, 0.70833333],\n       [0.94444444, 0.75      , 0.96610169, 0.875     ],\n       [0.94444444, 0.25      , 1.        , 0.91666667],\n       [0.47222222, 0.08333333, 0.6779661 , 0.58333333],\n       [0.72222222, 0.5       , 0.79661017, 0.91666667],\n       [0.36111111, 0.33333333, 0.66101695, 0.79166667],\n       [0.94444444, 0.33333333, 0.96610169, 0.79166667],\n       [0.55555556, 0.29166667, 0.66101695, 0.70833333],\n       [0.66666667, 0.54166667, 0.79661017, 0.83333333],\n       [0.80555556, 0.5       , 0.84745763, 0.70833333],\n       [0.52777778, 0.33333333, 0.6440678 , 0.70833333],\n       [0.5       , 0.41666667, 0.66101695, 0.70833333],\n       [0.58333333, 0.33333333, 0.77966102, 0.83333333],\n       [0.80555556, 0.41666667, 0.81355932, 0.625     ],\n       [0.86111111, 0.33333333, 0.86440678, 0.75      ],\n       [1.        , 0.75      , 0.91525424, 0.79166667],\n       [0.58333333, 0.33333333, 0.77966102, 0.875     ],\n       [0.55555556, 0.33333333, 0.69491525, 0.58333333],\n       [0.5       , 0.25      , 0.77966102, 0.54166667],\n       [0.94444444, 0.41666667, 0.86440678, 0.91666667],\n       [0.55555556, 0.58333333, 0.77966102, 0.95833333],\n       [0.58333333, 0.45833333, 0.76271186, 0.70833333],\n       [0.47222222, 0.41666667, 0.6440678 , 0.70833333],\n       [0.72222222, 0.45833333, 0.74576271, 0.83333333],\n       [0.66666667, 0.45833333, 0.77966102, 0.95833333],\n       [0.72222222, 0.45833333, 0.69491525, 0.91666667],\n       [0.41666667, 0.29166667, 0.69491525, 0.75      ],\n       [0.69444444, 0.5       , 0.83050847, 0.91666667],\n       [0.66666667, 0.54166667, 0.79661017, 1.        ],\n       [0.66666667, 0.41666667, 0.71186441, 0.91666667],\n       [0.55555556, 0.20833333, 0.6779661 , 0.75      ],\n       [0.61111111, 0.41666667, 0.71186441, 0.79166667],\n       [0.52777778, 0.58333333, 0.74576271, 0.91666667],\n       [0.44444444, 0.41666667, 0.69491525, 0.70833333]])"
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "scaler.transform(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 4)\n",
    "# y_train = y_train.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "model = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy',\n",
    "              optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1651 - accuracy: 0.3250\n",
      "Epoch 2/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1414 - accuracy: 0.3250\n",
      "Epoch 3/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1264 - accuracy: 0.3250\n",
      "Epoch 4/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.1124 - accuracy: 0.3250\n",
      "Epoch 5/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0996 - accuracy: 0.3250\n",
      "Epoch 6/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0899 - accuracy: 0.3250\n",
      "Epoch 7/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 1.0806 - accuracy: 0.3250\n",
      "Epoch 8/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0717 - accuracy: 0.3000\n",
      "Epoch 9/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0624 - accuracy: 0.2083\n",
      "Epoch 10/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0517 - accuracy: 0.1000\n",
      "Epoch 11/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0404 - accuracy: 0.1083\n",
      "Epoch 12/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0315 - accuracy: 0.1583\n",
      "Epoch 13/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0224 - accuracy: 0.2583\n",
      "Epoch 14/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0115 - accuracy: 0.4083\n",
      "Epoch 15/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.0005 - accuracy: 0.5333\n",
      "Epoch 16/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9894 - accuracy: 0.6333\n",
      "Epoch 17/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9776 - accuracy: 0.6500\n",
      "Epoch 18/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9652 - accuracy: 0.6500\n",
      "Epoch 19/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9514 - accuracy: 0.6583\n",
      "Epoch 20/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9376 - accuracy: 0.6583\n",
      "Epoch 21/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9223 - accuracy: 0.6583\n",
      "Epoch 22/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.9059 - accuracy: 0.6583\n",
      "Epoch 23/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8877 - accuracy: 0.6583\n",
      "Epoch 24/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8682 - accuracy: 0.6583\n",
      "Epoch 25/200\n",
      "4/4 [==============================] - 0s 667us/step - loss: 0.8466 - accuracy: 0.6583\n",
      "Epoch 26/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8253 - accuracy: 0.6583\n",
      "Epoch 27/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8020 - accuracy: 0.6583\n",
      "Epoch 28/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7785 - accuracy: 0.6583\n",
      "Epoch 29/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7545 - accuracy: 0.6583\n",
      "Epoch 30/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.6583\n",
      "Epoch 31/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.6583\n",
      "Epoch 32/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6857 - accuracy: 0.6583\n",
      "Epoch 33/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6616 - accuracy: 0.6583\n",
      "Epoch 34/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6583\n",
      "Epoch 35/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6033 - accuracy: 0.6583\n",
      "Epoch 36/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.6583\n",
      "Epoch 37/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5616 - accuracy: 0.6583\n",
      "Epoch 38/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.6583\n",
      "Epoch 39/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5304 - accuracy: 0.6583\n",
      "Epoch 40/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.6583\n",
      "Epoch 41/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5020 - accuracy: 0.7000\n",
      "Epoch 42/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7250\n",
      "Epoch 43/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7750\n",
      "Epoch 44/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.8333\n",
      "Epoch 45/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4552 - accuracy: 0.8500\n",
      "Epoch 46/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4442 - accuracy: 0.9000\n",
      "Epoch 47/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.9167\n",
      "Epoch 48/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4211 - accuracy: 0.9250\n",
      "Epoch 49/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4108 - accuracy: 0.9167\n",
      "Epoch 50/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4018 - accuracy: 0.9167\n",
      "Epoch 51/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.9167\n",
      "Epoch 52/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3845 - accuracy: 0.9417\n",
      "Epoch 53/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3761 - accuracy: 0.9667\n",
      "Epoch 54/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3678 - accuracy: 0.9667\n",
      "Epoch 55/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3593 - accuracy: 0.9667\n",
      "Epoch 56/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.9500\n",
      "Epoch 57/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.9667\n",
      "Epoch 58/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3366 - accuracy: 0.9667\n",
      "Epoch 59/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3291 - accuracy: 0.9667\n",
      "Epoch 60/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.9667\n",
      "Epoch 61/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3146 - accuracy: 0.9667\n",
      "Epoch 62/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3078 - accuracy: 0.9667\n",
      "Epoch 63/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.9667\n",
      "Epoch 64/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2940 - accuracy: 0.9750\n",
      "Epoch 65/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.9750\n",
      "Epoch 66/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2806 - accuracy: 0.9667\n",
      "Epoch 67/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2744 - accuracy: 0.9750\n",
      "Epoch 68/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2687 - accuracy: 0.9750\n",
      "Epoch 69/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9750\n",
      "Epoch 70/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2552 - accuracy: 0.9750\n",
      "Epoch 71/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2508 - accuracy: 0.9667\n",
      "Epoch 72/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9750\n",
      "Epoch 73/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.9750\n",
      "Epoch 74/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9750\n",
      "Epoch 75/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9750\n",
      "Epoch 76/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.9750\n",
      "Epoch 77/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.9750\n",
      "Epoch 78/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.9667\n",
      "Epoch 79/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.9750\n",
      "Epoch 80/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.9750\n",
      "Epoch 81/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.9750\n",
      "Epoch 82/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.9667\n",
      "Epoch 83/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.9667\n",
      "Epoch 84/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9750\n",
      "Epoch 85/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.9750\n",
      "Epoch 86/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.9750\n",
      "Epoch 87/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.9750\n",
      "Epoch 88/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9750\n",
      "Epoch 89/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1657 - accuracy: 0.9750\n",
      "Epoch 90/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1617 - accuracy: 0.9750\n",
      "Epoch 91/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1598 - accuracy: 0.9750\n",
      "Epoch 92/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1561 - accuracy: 0.9750\n",
      "Epoch 93/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9750\n",
      "Epoch 94/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1511 - accuracy: 0.9750\n",
      "Epoch 95/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.9750\n",
      "Epoch 96/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.1442 - accuracy: 0.9750\n",
      "Epoch 97/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9667\n",
      "Epoch 98/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1385 - accuracy: 0.9750\n",
      "Epoch 99/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9750\n",
      "Epoch 100/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1348 - accuracy: 0.9833\n",
      "Epoch 101/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.9750\n",
      "Epoch 102/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1303 - accuracy: 0.9750\n",
      "Epoch 103/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1279 - accuracy: 0.9750\n",
      "Epoch 104/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1263 - accuracy: 0.9750\n",
      "Epoch 105/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9833\n",
      "Epoch 106/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1273 - accuracy: 0.9667\n",
      "Epoch 107/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.1206 - accuracy: 0.9750\n",
      "Epoch 108/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.1204 - accuracy: 0.9750\n",
      "Epoch 109/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1189 - accuracy: 0.9750\n",
      "Epoch 110/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9583\n",
      "Epoch 111/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9750\n",
      "Epoch 112/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1162 - accuracy: 0.9750\n",
      "Epoch 113/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1126 - accuracy: 0.9750\n",
      "Epoch 114/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1096 - accuracy: 0.9750\n",
      "Epoch 115/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9750\n",
      "Epoch 116/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9750\n",
      "Epoch 117/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1049 - accuracy: 0.9750\n",
      "Epoch 118/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1040 - accuracy: 0.9750\n",
      "Epoch 119/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9750\n",
      "Epoch 120/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.9750\n",
      "Epoch 121/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.9750\n",
      "Epoch 122/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0980 - accuracy: 0.9750\n",
      "Epoch 123/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0949 - accuracy: 0.9750\n",
      "Epoch 124/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9750\n",
      "Epoch 125/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0927 - accuracy: 0.9750\n",
      "Epoch 126/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0919 - accuracy: 0.9833\n",
      "Epoch 127/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9750\n",
      "Epoch 128/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0906 - accuracy: 0.9750\n",
      "Epoch 129/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0914 - accuracy: 0.9750\n",
      "Epoch 130/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9833\n",
      "Epoch 131/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0871 - accuracy: 0.9750\n",
      "Epoch 132/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0878 - accuracy: 0.9750\n",
      "Epoch 133/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9750\n",
      "Epoch 134/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9750\n",
      "Epoch 135/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0837 - accuracy: 0.9833\n",
      "Epoch 136/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0827 - accuracy: 0.9750\n",
      "Epoch 137/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0820 - accuracy: 0.9750\n",
      "Epoch 138/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9750\n",
      "Epoch 139/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9750\n",
      "Epoch 140/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0822 - accuracy: 0.9750\n",
      "Epoch 141/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0810 - accuracy: 0.9750\n",
      "Epoch 142/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.9750\n",
      "Epoch 143/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9750\n",
      "Epoch 144/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9750\n",
      "Epoch 145/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9750\n",
      "Epoch 146/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9750\n",
      "Epoch 147/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0761 - accuracy: 0.9750\n",
      "Epoch 148/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0757 - accuracy: 0.9750\n",
      "Epoch 149/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9750\n",
      "Epoch 150/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9750\n",
      "Epoch 151/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0777 - accuracy: 0.9750\n",
      "Epoch 152/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0745 - accuracy: 0.9750\n",
      "Epoch 153/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9750\n",
      "Epoch 154/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0752 - accuracy: 0.9750\n",
      "Epoch 155/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0731 - accuracy: 0.9750\n",
      "Epoch 156/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0724 - accuracy: 0.9750\n",
      "Epoch 157/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0722 - accuracy: 0.9750\n",
      "Epoch 158/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9750\n",
      "Epoch 159/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0725 - accuracy: 0.9750\n",
      "Epoch 160/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0709 - accuracy: 0.9750\n",
      "Epoch 161/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9750\n",
      "Epoch 162/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0716 - accuracy: 0.9750\n",
      "Epoch 163/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0751 - accuracy: 0.9750\n",
      "Epoch 164/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0713 - accuracy: 0.9833\n",
      "Epoch 165/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9750\n",
      "Epoch 166/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0721 - accuracy: 0.9750\n",
      "Epoch 167/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9750\n",
      "Epoch 168/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9750\n",
      "Epoch 169/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 170/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9750\n",
      "Epoch 171/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9750\n",
      "Epoch 172/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9750\n",
      "Epoch 173/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9750\n",
      "Epoch 174/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9750\n",
      "Epoch 175/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9750\n",
      "Epoch 176/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9750\n",
      "Epoch 177/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0699 - accuracy: 0.9583\n",
      "Epoch 178/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0692 - accuracy: 0.9583\n",
      "Epoch 179/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9750\n",
      "Epoch 180/200\n",
      "4/4 [==============================] - 0s 907us/step - loss: 0.0708 - accuracy: 0.9750\n",
      "Epoch 181/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0681 - accuracy: 0.9750\n",
      "Epoch 182/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9750\n",
      "Epoch 183/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9750\n",
      "Epoch 184/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0677 - accuracy: 0.9750\n",
      "Epoch 185/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9750\n",
      "Epoch 186/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9750\n",
      "Epoch 187/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9833\n",
      "Epoch 188/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9833\n",
      "Epoch 189/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9750\n",
      "Epoch 190/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0658 - accuracy: 0.9750\n",
      "Epoch 191/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9833\n",
      "Epoch 192/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9833\n",
      "Epoch 193/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9750\n",
      "Epoch 194/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 195/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0654 - accuracy: 0.9750\n",
      "Epoch 196/200\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9750\n",
      "Epoch 197/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9750\n",
      "Epoch 198/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0673 - accuracy: 0.9750\n",
      "Epoch 199/200\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9750\n",
      "Epoch 200/200\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.0645 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2a3cbb2d848>"
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[3.6857653e-04, 9.8482937e-01, 1.4802096e-02],\n       [9.9989367e-01, 1.0576563e-04, 5.6764662e-07],\n       [9.2860762e-12, 1.6156935e-05, 9.9998379e-01],\n       [2.6981471e-04, 9.5124400e-01, 4.8486233e-02],\n       [2.0289513e-04, 9.7897971e-01, 2.0817349e-02]], dtype=float32)"
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 0, 2, 1, 1])"
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 저장"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x000002A3CBC58708> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.0810 - accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "loss_value, accuracy_value = model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "M_FILE = r'irisModel.h5'\n",
    "W_FILE = r'irisWeight.h5'\n",
    "if accuracy_value >= 0.96:\n",
    "    save_model(model, M_FILE)\n",
    "    model.save_weights(W_FILE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 복원\n",
    "- load_model(모델 파일 또는 모델 폴더명)\n",
    "- Sequential.load_weights(가중치 파일 또는 폴더명)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_88 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 3)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 303\n",
      "Trainable params: 303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 복원\n",
    "model_new = load_model(r'./irisModel.h5')\n",
    "model_new.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "# 가중치 복원(구조는 똑같아야함)\n",
    "new_model = Sequential()\n",
    "new_model.add(Dense(10, activation='relu', input_shape=(4,)))\n",
    "new_model.add(Dense(10, activation='relu'))\n",
    "new_model.add(Dense(10, activation='relu'))\n",
    "new_model.add(Dense(3, activation='softmax'))\n",
    "new_model.load_weights(W_FILE)\n",
    "\n",
    "new_model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy',\n",
    "                  optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step - loss: 0.0810 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.08103922754526138, 0.9666666388511658]"
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}